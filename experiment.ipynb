{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "Import the necessary libraries, including os, PIL, and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\rawframes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_file_path):\n",
    "    # open and load the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def load_images(folder_path, num_images=None):\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "                if (num_images) and (len(image_files) == num_images):\n",
    "                    break\n",
    "    return image_files\n",
    "\n",
    "def display_images(image_files):\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        img = Image.open(image_file)\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(img )\n",
    "        plt.title(os.path.basename(image_file))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def load_and_display_images(folder_path,  num_images=None):\n",
    "    \"\"\"\n",
    "    Load and display images from the specified folder.\n",
    "\n",
    "    :param folder_path: Path to the folder containing images.\n",
    "    :param num_images: Number of images to display.\n",
    "    \"\"\"\n",
    "    image_files = load_images(folder_path, num_images)\n",
    "    display_images(image_files)\n",
    "\n",
    "\n",
    "def load_and_display_images_with_bb(training_json_dict, video_id, num_images=None, save_folder=None, display_images=True):\n",
    "    training_keys = list(training_json_dict.keys())\n",
    "    dict_image_data = training_json_dict[training_keys[2]]\n",
    "    dict_annotation_data = training_json_dict[training_keys[3]]\n",
    "\n",
    "    images_df = pd.DataFrame(dict_image_data)\n",
    "    images_df = images_df[images_df['video_id'] == video_id]\n",
    "\n",
    "    annotation_df = pd.DataFrame(dict_annotation_data)\n",
    "\n",
    "    images_list = list(images_df.file_name)\n",
    "    if not num_images:\n",
    "        num_images = len(images_list)\n",
    "\n",
    "    image_arrays = []\n",
    "    for i, image_name in tqdm(enumerate(images_list[:num_images])):\n",
    "        image_id = int(images_df[images_df['file_name'] == image_name].id)\n",
    "        bbox = list(annotation_df[annotation_df['image_id'] == image_id]['bbox'])[0]\n",
    "        image_array = np.array(Image.open(os.path.join(dataset_path, image_name)))\n",
    "        image_arrays.append(image_array)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image_array)\n",
    "        plt.gca().add_patch(plt.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], edgecolor='green', facecolor='none', linewidth=2))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if save_folder:\n",
    "            if not os.path.exists(save_folder):\n",
    "                os.makedirs(save_folder)\n",
    "            plt.savefig(os.path.join(save_folder, os.path.basename(image_name)))\n",
    "        \n",
    "        if display_images:\n",
    "            plt.show()\n",
    "\n",
    "def buv_json_to_csv(buv_json_file, output_csv_file, two_points_format=True, only_train_frames=False):\t\n",
    "    json_dict = load_json(buv_json_file)\n",
    "    dict_keys = list(json_dict.keys())\n",
    "    dict_image_data = json_dict[dict_keys[2]]\n",
    "    dict_annotation_data = json_dict[dict_keys[3]]\n",
    "\n",
    "    images_df = pd.DataFrame(dict_image_data)\n",
    "    if only_train_frames:\n",
    "        images_df = images_df[images_df['is_vid_train_frame'] == True]\n",
    "\n",
    "    annotation_df = pd.DataFrame(dict_annotation_data)\n",
    "\n",
    "\n",
    "    images_list = list(images_df.file_name)\n",
    "    print('image_list_size: ', len(images_list))\n",
    "\n",
    "    images_to_ignore_list = ['benign/x66ef02e7f1b9a0ef', 'benign/x63c9ba1377f35bf6', 'benign/x5a1c46ec6377e946']\n",
    "\n",
    "    with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['img_file', 'x1', 'y1', 'x2', 'y2', 'class_name']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "    \n",
    "        for image_name in tqdm(images_list):\n",
    "\n",
    "            ignore = False\n",
    "            for image_to_ignore in images_to_ignore_list:\n",
    "                if image_to_ignore in image_name:\n",
    "                    ignore = True\n",
    "            if ignore:\n",
    "                print(f'Image {image_name} is ignored')\n",
    "                continue\n",
    "\n",
    "            image_id = int(images_df[images_df['file_name'] == image_name].id)\n",
    "            bbox = list(annotation_df[annotation_df['image_id'] == image_id]['bbox'])[0]\n",
    "\n",
    "            if two_points_format:\n",
    "                writer.writerow({\n",
    "                    'img_file': os.path.join(dataset_path, image_name),\n",
    "                    'x1': bbox[0] if bbox[2]>=0 else bbox[0] + bbox[2],\n",
    "                    'y1': bbox[1] if bbox[3]>=0 else bbox[1] + bbox[3],\n",
    "                    'x2': bbox[0] + bbox[2] if bbox[2]>=0 else bbox[0],\n",
    "                    'y2': bbox[1] + bbox[3] if bbox[3]>=0 else bbox[1],\n",
    "                    'class_name': 'Lesion'\n",
    "                })\n",
    "            else:\n",
    "                writer.writerow({\n",
    "                            'img_file': os.path.join(dataset_path, image_name),\n",
    "                            'x1': bbox[0],\n",
    "                            'y1': bbox[1],\n",
    "                            'x2': bbox[2],\n",
    "                            'y2': bbox[3],\n",
    "                            'class_name': 'Lesion'\n",
    "                        })\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_json_file = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\imagenet_vid_train_15frames.json'\n",
    "training_csv_file = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\train_annotations_2.csv'\n",
    "\n",
    "#buv_json_to_csv(training_json_file, training_csv_file, only_train_frames=True)\n",
    "\n",
    "validation_json_file = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\imagenet_vid_val.json'\n",
    "validation_csv_file = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\val_annotations.csv'\n",
    "\n",
    "#buv_json_to_csv(validation_json_file, validation_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_json_dict = load_json(r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\imagenet_vid_train_15frames.json')\n",
    "video_id = 63\n",
    "save_path = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\example_images\\63'\n",
    "load_and_display_images_with_bb(training_json_dict, video_id, save_folder=save_path, display_images=False)\n",
    "\n",
    "folder_path = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\rawframes\\benign\\2cda21c3aab26332'\n",
    "#load_and_display_images(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with the .json data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_path = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\rawframes\\benign'\n",
    "video_name = os.listdir(folder_path)\n",
    "file_name = os.listdir(os.path.join(folder_path,video_name[0]))\n",
    "\n",
    "training_json_dict = load_json(r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\imagenet_vid_train_15frames.json')\n",
    "training_keys = list(training_json_dict.keys())\n",
    "print(training_keys)\n",
    "\n",
    "video_index = 0\n",
    "\n",
    "video_name = training_json_dict[training_keys[1]][video_index]['name']\n",
    "video_folder_path = os.listdir(os.path.join(dataset_path,video_name))\n",
    "\n",
    "# print the loaded data\n",
    "print(list(training_json_dict.keys()))\n",
    "print(training_json_dict[list(training_json_dict.keys())[0]][0])\n",
    "print(training_json_dict[list(training_json_dict.keys())[1]][0])\n",
    "print(training_json_dict[list(training_json_dict.keys())[2]][29])\n",
    "print(training_json_dict[list(training_json_dict.keys())[3]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retinanet visualisation and Evaluation on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./pytorch-retinanet')\n",
    "from torchvision import transforms\n",
    "from retinanet import model\n",
    "from retinanet.dataloader import CocoDataset, Resizer, Normalizer\n",
    "\n",
    "model_path = r\"C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\retinanet_checkpoints\\coco_resnet_50_map_0_335_state_dict.pt\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "retinanet = model.resnet50(num_classes=80)\n",
    "retinanet.load_state_dict(torch.load(model_path, map_location=device))\n",
    "retinanet = retinanet.to(device)\n",
    "\n",
    "# Transform the image\n",
    "transform = transforms.Compose([Normalizer(), Resizer()])\n",
    "# Load the image as a PIL image\n",
    "folder_path = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\rawframes\\benign\\2cda21c3aab26332'\n",
    "image_path = load_images(folder_path)[0]\n",
    "print(image_path)\n",
    "image_pil = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Transform the image\n",
    "sample = {'img': np.array(image_pil), 'annot': np.zeros((0, 5))}\n",
    "transformed_sample = transform(sample)\n",
    "transformed_image = transformed_sample['img'].permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "retinanet.eval()\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    scores, classification, transformed_anchors = retinanet(transformed_image)\n",
    "\n",
    "# Process the results\n",
    "for idx in range(scores.shape[0]):\n",
    "    if scores[idx] > 0.5:  # Threshold for detection\n",
    "        bbox = transformed_anchors[idx, :]\n",
    "        x1, y1, x2, y2 = bbox[0].item(), bbox[1].item(), bbox[2].item(), bbox[3].item()\n",
    "        label = int(classification[idx])\n",
    "        print(f\"Detected object with score {scores[idx]:.2f} at [{x1}, {y1}, {x2}, {y2}] with label {label}\")\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(image_pil)\n",
    "        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor='red', facecolor='none', linewidth=2))\n",
    "        plt.title(f'Detected object with score {scores[idx]:.2f}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_directory = r\"C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\pytorch-retinanet\\trained_networks\"\n",
    "sys.path.append('./pytorch-retinanet')\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from retinanet.dataloader import CSVDataset, collater, Resizer, AspectRatioBasedSampler, UnNormalizer, Normalizer\n",
    "from retinanet import csv_eval\t\n",
    "\n",
    "csv_val = r\"C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\val_annotations.csv\"\n",
    "csv_classes = r\"C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\class_name.csv\"\n",
    "dataset_val = CSVDataset(train_file=csv_val, class_list=csv_classes, transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=1, drop_last=False)\n",
    "dataloader_val = DataLoader(dataset_val, num_workers=1, collate_fn=collater, batch_sampler=sampler_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_caption(image, box, caption):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)\n",
    "\n",
    "def visualize_network_outputs(retinanet, dataloader_val, dataset_val, num_images=10, show_ground_truth=True):\n",
    "    unnormalize = UnNormalizer()\n",
    "    retinanet.eval()\n",
    "\n",
    "    for idx, data in enumerate(dataloader_val):\n",
    "        if idx >= num_images:\n",
    "            break\n",
    "        with torch.no_grad():\n",
    "            st = time.time()\n",
    "            if torch.cuda.is_available():\n",
    "                scores, classification, transformed_anchors = retinanet(data['img'].cuda().float())\n",
    "            else:\n",
    "                scores, classification, transformed_anchors = retinanet(data['img'].float())\n",
    "            print('Elapsed time: {}'.format(time.time() - st))\n",
    "            idxs = np.where(scores.cpu() > 0.5)\n",
    "            img = np.array(255 * unnormalize(data['img'][0, :, :, :])).copy()\n",
    "\n",
    "            img[img < 0] = 0\n",
    "            img[img > 255] = 255\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "            img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            for j in range(idxs[0].shape[0]):\n",
    "                bbox = transformed_anchors[idxs[0][j], :]\n",
    "                x1 = int(bbox[0])\n",
    "                y1 = int(bbox[1])\n",
    "                x2 = int(bbox[2])\n",
    "                y2 = int(bbox[3])\n",
    "                label_name = dataset_val.labels[int(classification[idxs[0][j]])]\n",
    "                #draw_caption(img, (x1, y1, x2, y2), label_name)\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "                print(label_name)\n",
    "\n",
    "            if show_ground_truth:\n",
    "                annotations = data['annot'][0]\n",
    "                for k in range(annotations.shape[0]):\n",
    "                    bbox = annotations[k, :4]\n",
    "                    x1 = int(bbox[0])\n",
    "                    y1 = int(bbox[1])\n",
    "                    x2 = int(bbox[2])\n",
    "                    y2 = int(bbox[3])\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            # Evaluate the image and print metrics\n",
    "            annotations = dataset_val.load_annotations(idx)\n",
    "            detections = np.concatenate([transformed_anchors[idxs[0], :].cpu().numpy(), scores[idxs[0]].cpu().numpy().reshape(-1, 1)], axis=1)\n",
    "            average_precisions = csv_eval.process_image(dataset_val[idx], retinanet, score_threshold=0.05, max_detections=1,)\n",
    "            print(f\"Image {idx + 1} Evaluation Metrics:\")\n",
    "            print(average_precisions[average_precisions[:, -1] == 0, :-1])\n",
    "\n",
    "model = os.path.join(models_directory, 'experiment_1\\csv_retinanet_19.pt')\n",
    "retinanet = torch.load(model)\n",
    "#visualize_network_outputs(retinanet, dataloader_val, dataset_val, num_images=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_1_directory = os.path.join(models_directory, 'experiment_1')\n",
    "experiment_2_directory = os.path.join(models_directory, 'experiment_2')\n",
    "\n",
    "\n",
    "def validate_and_save(experiment_directory, coco_metrics=True, plot_froc=True, validation_json_file=None):\n",
    "    for model_name in os.listdir(experiment_directory):\n",
    "\n",
    "        if not model_name.endswith('.pt'):\n",
    "            continue\n",
    "\n",
    "        print(model_name)\n",
    "        if coco_metrics:\n",
    "            output_json_file = os.path.join(experiment_directory, f'{model_name}_coco_metrics.json')\n",
    "        else:\n",
    "            output_json_file = os.path.join(experiment_directory, f'{model_name}_metrics.json')\n",
    "\n",
    "        model_path = os.path.join(experiment_directory, model_name)\n",
    "        retinanet = torch.load(model_path)\n",
    "        if coco_metrics:\n",
    "            if not validation_json_file:\n",
    "                raise ValueError('validation_json_file must be provided when using COCO metrics')\n",
    "            metrics_list = csv_eval.evaluate_coco_metrics(dataset_val, retinanet, buv_json_file=validation_json_file, model_path=model_path),\n",
    "        else:\n",
    "            metrics_list = csv_eval.evaluate(dataset_val,retinanet,iou_threshold=0.5,score_threshold=0.05,max_detections=1,save_path=None)\n",
    "        \n",
    "        if not os.path.exists(output_json_file):\n",
    "            with open(output_json_file, 'w') as f:\n",
    "                json.dump(metrics_list, f, indent=4)\n",
    "\n",
    "        if plot_froc:\n",
    "            thresholds = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "            csv_eval.evaluate_froc(dataset_val, retinanet, buv_json_file=validation_json_file, model_path=model_path, score_thresholds=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_json_file = r'C:\\Users\\zaid-\\OneDrive\\Desktop\\PMSD\\Implementation\\Miccai 2022 BUV Dataset\\imagenet_vid_val.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_and_save(experiment_1_directory, validation_json_file=validation_json_file)\n",
    "#validate_and_save(experiment_2_directory, validation_json_file=validation_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PMSD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
